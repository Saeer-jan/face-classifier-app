{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T10:51:38.325192500Z",
     "start_time": "2025-12-14T10:51:36.617103800Z"
    }
   },
   "cell_type": "code",
   "source": "pip install tensorflow numpy matplotlib opencv-python",
   "id": "95c546f6a801b07c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\saeer jan\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\saeer jan\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\saeer jan\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\saeer jan\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: optree in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: namex in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\saeer jan\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\saeer jan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T12:03:29.481858700Z",
     "start_time": "2025-12-14T10:51:38.574864300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, applications, models, callbacks\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & CONFIGURATION (Your Local Path)\n",
    "# ==========================================\n",
    "# This matches your screenshot path\n",
    "DATA_DIR = r\"C:\\Users\\Saeer Jan\\Desktop\\project\\Images\\Images\\new\"\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10  # You can increase this to 15 if you have a GPU\n",
    "\n",
    "print(f\"üöÄ Project Started! Looking for data in: {DATA_DIR}\")\n",
    "\n",
    "# Check if path works\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(\"‚ùå ERROR: Could not find the folder!\")\n",
    "    print(f\"Please check if this path is correct: {DATA_DIR}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# 2. HANDLE IMBALANCE (The Class Weights)\n",
    "# ==========================================\n",
    "data_dir = pathlib.Path(DATA_DIR)\n",
    "count_frontal = len(list(data_dir.glob('frontal/*')))\n",
    "count_profile = len(list(data_dir.glob('profile/*')))\n",
    "\n",
    "# Fallback if folders are named differently (e.g. Capital letters)\n",
    "if count_frontal == 0: count_frontal = len(list(data_dir.glob('Frontal/*')))\n",
    "if count_profile == 0: count_profile = len(list(data_dir.glob('Profile/*')))\n",
    "\n",
    "total_images = count_frontal + count_profile\n",
    "\n",
    "print(f\"üìä Stats: Frontal={count_frontal}, Profile={count_profile}, Total={total_images}\")\n",
    "\n",
    "if total_images == 0:\n",
    "    print(\"‚ùå Error: No images found. Check folder structure.\")\n",
    "    exit()\n",
    "\n",
    "# Calculate Weights\n",
    "weight_0 = (1 / count_frontal) * (total_images / 2.0)\n",
    "weight_1 = (1 / count_profile) * (total_images / 2.0)\n",
    "class_weights = {0: weight_0, 1: weight_1}\n",
    "\n",
    "print(f\"‚öñÔ∏è Balanced Weights: {class_weights}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. LOAD DATA\n",
    "# ==========================================\n",
    "print(\"üîÑ Loading Images...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "# Optimization for Local PC\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# ==========================================\n",
    "# 4. BUILD MODEL (ResNet50)\n",
    "# ==========================================\n",
    "print(\"üß† Building ResNet50 Brain...\")\n",
    "base_model = applications.ResNet50(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=IMG_SIZE + (3,))\n",
    "x = layers.RandomFlip(\"horizontal\")(inputs) # Augmentation\n",
    "x = applications.resnet50.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ==========================================\n",
    "# 5. TRAIN & SAVE\n",
    "# ==========================================\n",
    "# Callbacks for safety\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_face_model.keras',  # Using .keras format to avoid warnings\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üî• Starting Training (This may take time on a laptop)...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ DONE! Model saved as 'best_face_model.keras'\")"
   ],
   "id": "f6f2dc199c0a893d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Project Started! Looking for data in: C:\\Users\\Saeer Jan\\Desktop\\project\\Images\\Images\\new\n",
      "üìä Stats: Frontal=5010, Profile=2004, Total=7014\n",
      "‚öñÔ∏è Balanced Weights: {0: 0.7, 1: 1.7499999999999998}\n",
      "üîÑ Loading Images...\n",
      "Found 7014 files belonging to 2 classes.\n",
      "Using 5612 files for training.\n",
      "Found 7014 files belonging to 2 classes.\n",
      "Using 1402 files for validation.\n",
      "üß† Building ResNet50 Brain...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001B[1m94765736/94765736\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 0us/step\n",
      "üî• Starting Training (This may take time on a laptop)...\n",
      "Epoch 1/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.7464 - loss: 0.6050\n",
      "Epoch 1: val_accuracy improved from None to 0.96291, saving model to best_face_model.keras\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m435s\u001B[0m 2s/step - accuracy: 0.8074 - loss: 0.4791 - val_accuracy: 0.9629 - val_loss: 0.2815\n",
      "Epoch 2/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9260 - loss: 0.2814\n",
      "Epoch 2: val_accuracy improved from 0.96291 to 0.98359, saving model to best_face_model.keras\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m467s\u001B[0m 3s/step - accuracy: 0.9424 - loss: 0.2446 - val_accuracy: 0.9836 - val_loss: 0.1657\n",
      "Epoch 3/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9692 - loss: 0.1779\n",
      "Epoch 3: val_accuracy improved from 0.98359 to 0.98716, saving model to best_face_model.keras\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m494s\u001B[0m 3s/step - accuracy: 0.9720 - loss: 0.1591 - val_accuracy: 0.9872 - val_loss: 0.1178\n",
      "Epoch 4/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9783 - loss: 0.1313\n",
      "Epoch 4: val_accuracy improved from 0.98716 to 0.99215, saving model to best_face_model.keras\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m492s\u001B[0m 3s/step - accuracy: 0.9831 - loss: 0.1185 - val_accuracy: 0.9922 - val_loss: 0.0889\n",
      "Epoch 5/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9869 - loss: 0.0993\n",
      "Epoch 5: val_accuracy improved from 0.99215 to 0.99501, saving model to best_face_model.keras\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m457s\u001B[0m 3s/step - accuracy: 0.9870 - loss: 0.0936 - val_accuracy: 0.9950 - val_loss: 0.0721\n",
      "Epoch 6/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9887 - loss: 0.0826\n",
      "Epoch 6: val_accuracy improved from 0.99501 to 0.99572, saving model to best_face_model.keras\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m377s\u001B[0m 2s/step - accuracy: 0.9888 - loss: 0.0774 - val_accuracy: 0.9957 - val_loss: 0.0589\n",
      "Epoch 7/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9887 - loss: 0.0719\n",
      "Epoch 7: val_accuracy did not improve from 0.99572\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m376s\u001B[0m 2s/step - accuracy: 0.9884 - loss: 0.0681 - val_accuracy: 0.9957 - val_loss: 0.0503\n",
      "Epoch 8/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9909 - loss: 0.0630\n",
      "Epoch 8: val_accuracy improved from 0.99572 to 0.99643, saving model to best_face_model.keras\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m383s\u001B[0m 2s/step - accuracy: 0.9906 - loss: 0.0588 - val_accuracy: 0.9964 - val_loss: 0.0437\n",
      "Epoch 9/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9932 - loss: 0.0525\n",
      "Epoch 9: val_accuracy improved from 0.99643 to 0.99715, saving model to best_face_model.keras\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m377s\u001B[0m 2s/step - accuracy: 0.9939 - loss: 0.0503 - val_accuracy: 0.9971 - val_loss: 0.0383\n",
      "Epoch 10/10\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.9941 - loss: 0.0489\n",
      "Epoch 10: val_accuracy did not improve from 0.99715\n",
      "\u001B[1m176/176\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m377s\u001B[0m 2s/step - accuracy: 0.9939 - loss: 0.0451 - val_accuracy: 0.9971 - val_loss: 0.0347\n",
      "\n",
      "‚úÖ DONE! Model saved as 'best_face_model.keras'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:49.842870300Z",
     "start_time": "2025-12-14T13:26:42.395780600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2  # OpenCV for reading images\n",
    "import os\n",
    "\n",
    "# 1. Load the model\n",
    "MODEL_PATH = 'best_face_model.keras'\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(\"‚ùå Model not found! Please run train.py first.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"üîÑ Loading model: {MODEL_PATH}...\")\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# 2. Function to predict\n",
    "def predict_face(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"‚ùå Image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Load and resize the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Fix colors\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    # Preprocess\n",
    "    img_array = np.expand_dims(img, axis=0)\n",
    "    img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    score = prediction[0][0]\n",
    "\n",
    "    print(f\"\\nüì∏ Analysis for: {image_path}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # 0 = Frontal, 1 = Profile (Based on your folder order)\n",
    "    if score > 0.5:\n",
    "        confidence = score * 100\n",
    "        print(f\"‚úÖ RESULT: PROFILE (Side View)\")\n",
    "        print(f\"üìä Confidence: {confidence:.2f}%\")\n",
    "    else:\n",
    "        confidence = (1 - score) * 100\n",
    "        print(f\"‚úÖ RESULT: FRONTAL (Front View)\")\n",
    "        print(f\"üìä Confidence: {confidence:.2f}%\")\n",
    "\n",
    "# ==========================================\n",
    "# CHANGE THIS TO TEST A NEW IMAGE\n",
    "# ==========================================\n",
    "# Put the path of a test image here:\n",
    "test_image_path = r\"C:\\Users\\Saeer Jan\\Pictures\\Camera Roll\\WIN_20251214_18_25_58_Pro.jpg\"\n",
    "\n",
    "predict_face(test_image_path)"
   ],
   "id": "f860218069fc31df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading model: best_face_model.keras...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A75EB84040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "\n",
      "üì∏ Analysis for: C:\\Users\\Saeer Jan\\Pictures\\Camera Roll\\WIN_20251214_18_25_58_Pro.jpg\n",
      "------------------------------\n",
      "‚úÖ RESULT: FRONTAL (Front View)\n",
      "üìä Confidence: 77.74%\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d540383ecc0220a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
